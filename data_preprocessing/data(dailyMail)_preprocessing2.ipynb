{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 'PBULISHED:, UPDATED:' 2차제거  && 특수문자제거 및 소문자만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120411\n",
      "120411\n"
     ]
    }
   ],
   "source": [
    "import unicodedata\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os import listdir\n",
    "\n",
    "result = pd.read_csv('dailymail_stories_preprocessing1.csv')\n",
    "\n",
    "# 해당값이 아닌것만 저장! 즉, 해당값 제거!\n",
    "# 변수에 따로 넣어줘야함!\n",
    "# result = result[result.index != 1]\n",
    "result[result.index != 1]\n",
    "\n",
    "print(len(result['story']))\n",
    "print(len(result['highlights']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "812\n",
      "119599\n",
      "119599\n"
     ]
    }
   ],
   "source": [
    "# 특수문자 제거 & 소문자 만들기\n",
    "def preprocess_sentence(line):\n",
    "\n",
    "    # creating a space between a word and the punctuation following it\n",
    "    # eg: \"he is a boy.\" => \"he is a boy .\"\n",
    "    # Reference:- https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\n",
    "    line = re.sub(r\"([?.!,¿])\", r\" \\1 \", line)\n",
    "    line = re.sub(r'[\" \"]+', \" \", line)\n",
    "\n",
    "    # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
    "    line = re.sub(r\"[^a-zA-Z0-9?.!,@%$¿]+\", \" \", line)\n",
    "\n",
    "    return line.strip().lower()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# PUBLISHED: & UPDATED: 2차 삭제!!!!!!!!\n",
    "useless_list = []\n",
    "for i, v in enumerate(result['story']):\n",
    "    if 'PUBLISHED:' in v or 'UPDATED:' in v :\n",
    "        useless_list.append(i)\n",
    "        result = result[result.index != i]\n",
    "    else:\n",
    "        result['story'][i] = preprocess_sentence(result['story'][i])\n",
    "        result['highlights'][i] = preprocess_sentence(result['highlights'][i])\n",
    "\n",
    "# 120,411 - (726 + 86) = 119,599\n",
    "print(len(useless_list))\n",
    "print(len(result['story']))\n",
    "print(len(result['highlights']))\n",
    "result.to_csv('dailymail_stories_preprocessing2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 중복값 체크1 (중복 제거 후 필요한만큼 데이터 저장)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중복체크 이전\n",
      "119599\n",
      "119599 \n",
      "\n",
      "story 중복체크 후 데이터 갯수\n",
      "119576\n",
      "119576 \n",
      "\n",
      "highlights 중복체크 후 데이터 갯수\n",
      "119151\n",
      "119151\n"
     ]
    }
   ],
   "source": [
    "duplicate_check = pd.read_csv('dailymail_stories_preprocessing2.csv').dropna()\n",
    "print('중복체크 이전')\n",
    "print(len(duplicate_check['story']))\n",
    "print(len(duplicate_check['highlights']), '\\n')\n",
    "\n",
    "duplicate_check = duplicate_check.drop_duplicates(subset = 'story')\n",
    "print('story 중복체크 후 데이터 갯수')\n",
    "print(len(duplicate_check['story']))\n",
    "print(len(duplicate_check['highlights']), '\\n')\n",
    "\n",
    "duplicate_check = duplicate_check.drop_duplicates(subset = 'highlights')\n",
    "print('highlights 중복체크 후 데이터 갯수')\n",
    "print(len(duplicate_check['story']))\n",
    "print(len(duplicate_check['highlights']))\n",
    "\n",
    "duplicate_check.to_csv('dailymail_stories_preprocessing2.csv', index = False)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dailymail 데이터 랜덤하게 섞고 6만개 데이터 저장(train+vali)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119151\n"
     ]
    }
   ],
   "source": [
    "dailymail_articles = pd.read_csv('dailymail_stories_preprocessing2.csv')\n",
    "print(len(dailymail_articles['story']))   #119151\n",
    "\n",
    "# The frac keyword argument specifies the fraction of rows to return in the random sample, so frac=1 means return all rows (in random order).\n",
    "# Here, specifying drop=True prevents .reset_index from creating a column containing the old index entries.\n",
    "dailymail_articles = dailymail_articles.sample(frac=1).reset_index(drop=True)\n",
    "dailymail_articles = dailymail_articles[:60000]\n",
    "dailymail_articles.to_csv('dailymail_stories.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train, test 분류(5만, 1만)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "dailymail_articles = pd.read_csv('dailymail_stories.csv')\n",
    "dailymail_articles_train = dailymail_articles[:50000]\n",
    "dailymail_articles_train.to_csv('dailymail_stories_train.csv', index=False)\n",
    "\n",
    "dailymail_articles_test = dailymail_articles[50000:]\n",
    "dailymail_articles_test.to_csv('dailymail_stories_test.csv', index=False)\n",
    "\n",
    "print(len(dailymail_articles_train['highlights']))\n",
    "print(len(dailymail_articles_test['story']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN, DAILYMAIL train_data 합치기!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n",
      "50000\n",
      "50000\n",
      "50000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "cnn_train = pd.read_csv('cnn_stories_train.csv').dropna()\n",
    "dailymail_train = pd.read_csv('dailymail_stories_train.csv').dropna()\n",
    "\n",
    "print(len(cnn_train['story']))\n",
    "print(len(cnn_train['highlights']))\n",
    "print(len(dailymail_train['story']))\n",
    "print(len(dailymail_train['highlights']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = cnn_train.append(dailymail_train, ignore_index = True)   #index값 순차적으로 설정! (0-99999)\n",
    "#print(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.to_csv('train_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN, DAILYMAIL test_data 합치기!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "cnn_test = pd.read_csv('cnn_stories_test.csv').dropna()\n",
    "dailymail_test = pd.read_csv('dailymail_stories_test.csv').dropna()\n",
    "\n",
    "print(len(cnn_test['story']))\n",
    "print(len(cnn_test['highlights']))\n",
    "print(len(dailymail_test['story']))\n",
    "print(len(dailymail_test['highlights']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = cnn_test.append(dailymail_test, ignore_index = True)   #index값 순차적으로 설정! (0-99999)\n",
    "#print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.to_csv('test_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 전체 중복값 체크"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000 100000\n",
      "100000 99999\n"
     ]
    }
   ],
   "source": [
    "check = pd.read_csv('train_data.csv').dropna()\n",
    "print(len(check['story']), len(check['highlights'])) \n",
    "\n",
    "\n",
    "story_data = check.drop_duplicates(subset = 'story')\n",
    "highlight_data = check.drop_duplicates(subset = 'highlights')\n",
    "print(len(story_data['story']), len(highlight_data['highlights']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 길이"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "congressman jared polis d colorado district 02 congressman jason chaffetz r utah district 03\n",
      "14\n",
      "2304\n",
      "100000\n",
      "757.25586\n",
      "[14, 26, 34, 39, 40, 46, 46, 48, 48, 49, 51, 53, 53, 54, 55, 56, 57, 59, 59, 60, 60, 64, 64, 64, 65, 66, 66, 68, 69, 69, 70, 71, 72, 72, 72, 73, 73, 73, 74, 74, 74, 75, 75, 75, 76, 76, 76, 78, 80, 80]\n"
     ]
    }
   ],
   "source": [
    "#story = pd.read_csv('test_data.csv').dropna()\n",
    "story = pd.read_csv('train_data.csv').dropna()\n",
    "\n",
    "h_count_list = []\n",
    "for h in story['story']:\n",
    "    c = len(h.split(' '))\n",
    "    h_count_list.append(c)\n",
    "    \n",
    "    if c ==14:\n",
    "        print(h)\n",
    "\n",
    "\n",
    "h_count_list.sort()\n",
    "print(min(h_count_list))\n",
    "print(max(h_count_list))\n",
    "print(len(h_count_list))\n",
    "print(sum(h_count_list)/len(h_count_list))\n",
    "print(h_count_list[:50])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
